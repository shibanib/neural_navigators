{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Regional Communication Analysis of Steinmetz Dataset\n",
    "\n",
    "This notebook analyzes interactions between brain regions, including:\n",
    "1. Inter-regional spike correlations\n",
    "2. LFP coherence between regions\n",
    "3. Information flow analysis\n",
    "4. Region-specific population dynamics\n",
    "5. Task-dependent connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal, stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_loader import SteinmetzDataLoader\n",
    "from neural_analysis import NeuralAnalyzer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize data loader and load session\n",
    "loader = SteinmetzDataLoader()\n",
    "loader.download_data()\n",
    "session_data = loader.load_session(11)  # Using session 11 as an example\n",
    "\n",
    "# Initialize neural analyzer\n",
    "analyzer = NeuralAnalyzer()\n",
    "\n",
    "print(\"Available brain regions:\", np.unique(session_data['brain_area_lfp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inter-regional Spike Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compute_region_correlations(spikes, brain_regions, time_window=(-0.5, 0.5), bin_size=0.01):\n",
    "    \"\"\"Compute correlations between neurons from different regions.\"\"\"\n",
    "    unique_regions = np.unique(brain_regions)\n",
    "    n_regions = len(unique_regions)\n",
    "    correlation_matrix = np.zeros((n_regions, n_regions))\n",
    "    \n",
    "    # Compute firing rates\n",
    "    time_bins = np.arange(time_window[0], time_window[1] + bin_size, bin_size)\n",
    "    firing_rates = loader.compute_firing_rates(spikes, time_bins)\n",
    "    \n",
    "    # Compute correlations between regions\n",
    "    for i, region1 in enumerate(unique_regions):\n",
    "        neurons1 = np.where(brain_regions == region1)[0]\n",
    "        rates1 = firing_rates[neurons1].mean(axis=0)\n",
    "        \n",
    "        for j, region2 in enumerate(unique_regions):\n",
    "            neurons2 = np.where(brain_regions == region2)[0]\n",
    "            rates2 = firing_rates[neurons2].mean(axis=0)\n",
    "            \n",
    "            correlation_matrix[i, j], _ = stats.pearsonr(rates1, rates2)\n",
    "    \n",
    "    return correlation_matrix, unique_regions\n",
    "\n",
    "# Example brain regions (replace with actual regions)\n",
    "example_regions = np.random.choice(['V1', 'V2', 'MT', 'LGN'], size=len(session_data['spikes']))\n",
    "\n",
    "# Compute and plot correlation matrix\n",
    "corr_matrix, regions = compute_region_correlations(session_data['spikes'], example_regions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, xticklabels=regions, yticklabels=regions,\n",
    "            cmap='RdBu_r', center=0, vmin=-1, vmax=1)\n",
    "plt.title('Inter-regional Spike Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LFP Coherence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compute_frequency_band_coherence(lfp1, lfp2, band_range=(4, 8), fs=100):\n",
    "    \"\"\"Compute coherence in specific frequency band (e.g., theta: 4-8 Hz).\"\"\"\n",
    "    f, Cxy = signal.coherence(lfp1, lfp2, fs=fs)\n",
    "    band_mask = (f >= band_range[0]) & (f <= band_range[1])\n",
    "    return np.mean(Cxy[band_mask])\n",
    "\n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 80)\n",
    "}\n",
    "\n",
    "# Compute coherence for each band between regions\n",
    "unique_areas = np.unique(session_data['brain_area_lfp'])\n",
    "n_areas = len(unique_areas)\n",
    "band_coherence = {band: np.zeros((n_areas, n_areas)) for band in bands}\n",
    "\n",
    "for band_name, freq_range in bands.items():\n",
    "    for i, area1 in enumerate(unique_areas):\n",
    "        for j, area2 in enumerate(unique_areas):\n",
    "            if i != j:\n",
    "                # Get LFP from both regions\n",
    "                lfp1 = session_data['lfp'][:, session_data['brain_area_lfp'] == area1].mean(axis=1)\n",
    "                lfp2 = session_data['lfp'][:, session_data['brain_area_lfp'] == area2].mean(axis=1)\n",
    "                \n",
    "                # Compute coherence\n",
    "                band_coherence[band_name][i, j] = compute_frequency_band_coherence(\n",
    "                    lfp1, lfp2, freq_range\n",
    "                )\n",
    "\n",
    "# Plot coherence matrices for each frequency band\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (band_name, coherence) in enumerate(band_coherence.items()):\n",
    "    sns.heatmap(coherence, xticklabels=unique_areas, yticklabels=unique_areas,\n",
    "                cmap='viridis', vmin=0, vmax=1, ax=axes[i])\n",
    "    axes[i].set_title(f'{band_name.capitalize()} Band Coherence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Information Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compute_granger_causality(signal1, signal2, max_lag=10):\n",
    "    \"\"\"Compute Granger causality between two signals.\"\"\"\n",
    "    from statsmodels.tsa.stattools import grangercausalitytests\n",
    "    \n",
    "    # Prepare data\n",
    "    data = np.column_stack([signal1, signal2])\n",
    "    \n",
    "    # Test Granger causality in both directions\n",
    "    gc_1to2 = grangercausalitytests(data, maxlag=max_lag, verbose=False)\n",
    "    gc_2to1 = grangercausalitytests(np.column_stack([signal2, signal1]), \n",
    "                                    maxlag=max_lag, verbose=False)\n",
    "    \n",
    "    # Extract test statistics\n",
    "    stats_1to2 = [gc_1to2[i+1][0]['ssr_chi2test'][1] for i in range(max_lag)]\n",
    "    stats_2to1 = [gc_2to1[i+1][0]['ssr_chi2test'][1] for i in range(max_lag)]\n",
    "    \n",
    "    return np.min(stats_1to2), np.min(stats_2to1)\n",
    "\n",
    "# Compute Granger causality between regions\n",
    "flow_matrix = np.zeros((n_areas, n_areas))\n",
    "\n",
    "for i, area1 in enumerate(unique_areas):\n",
    "    for j, area2 in enumerate(unique_areas):\n",
    "        if i != j:\n",
    "            lfp1 = session_data['lfp'][:, session_data['brain_area_lfp'] == area1].mean(axis=1)\n",
    "            lfp2 = session_data['lfp'][:, session_data['brain_area_lfp'] == area2].mean(axis=1)\n",
    "            \n",
    "            gc_1to2, gc_2to1 = compute_granger_causality(lfp1, lfp2)\n",
    "            flow_matrix[i, j] = -np.log10(gc_1to2)\n",
    "\n",
    "# Plot information flow matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(flow_matrix, xticklabels=unique_areas, yticklabels=unique_areas,\n",
    "            cmap='YlOrRd')\n",
    "plt.title('Information Flow between Regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task-Dependent Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_task_dependent_connectivity(lfp_data, brain_areas, time_window=(-0.5, 0.5)):\n",
    "    \"\"\"Analyze how regional connectivity changes during the task.\"\"\"\n",
    "    # Split time window into early and late periods\n",
    "    mid_point = len(lfp_data) // 2\n",
    "    early_data = lfp_data[:mid_point]\n",
    "    late_data = lfp_data[mid_point:]\n",
    "    \n",
    "    # Compute coherence for each period\n",
    "    unique_areas = np.unique(brain_areas)\n",
    "    n_areas = len(unique_areas)\n",
    "    early_coherence = np.zeros((n_areas, n_areas))\n",
    "    late_coherence = np.zeros((n_areas, n_areas))\n",
    "    \n",
    "    for i, area1 in enumerate(unique_areas):\n",
    "        for j, area2 in enumerate(unique_areas):\n",
    "            if i != j:\n",
    "                # Early period\n",
    "                lfp1_early = early_data[:, brain_areas == area1].mean(axis=1)\n",
    "                lfp2_early = early_data[:, brain_areas == area2].mean(axis=1)\n",
    "                f, Cxy = signal.coherence(lfp1_early, lfp2_early, fs=100)\n",
    "                early_coherence[i, j] = np.mean(Cxy)\n",
    "                \n",
    "                # Late period\n",
    "                lfp1_late = late_data[:, brain_areas == area1].mean(axis=1)\n",
    "                lfp2_late = late_data[:, brain_areas == area2].mean(axis=1)\n",
    "                f, Cxy = signal.coherence(lfp1_late, lfp2_late, fs=100)\n",
    "                late_coherence[i, j] = np.mean(Cxy)\n",
    "    \n",
    "    return early_coherence, late_coherence, unique_areas\n",
    "\n",
    "# Analyze task-dependent connectivity\n",
    "early_coh, late_coh, areas = analyze_task_dependent_connectivity(\n",
    "    session_data['lfp'],\n",
    "    session_data['brain_area_lfp']\n",
    ")\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "sns.heatmap(early_coh, xticklabels=areas, yticklabels=areas,\n",
    "            cmap='viridis', vmin=0, vmax=1, ax=ax1)\n",
    "ax1.set_title('Early Task Period Coherence')\n",
    "\n",
    "sns.heatmap(late_coh, xticklabels=areas, yticklabels=areas,\n",
    "            cmap='viridis', vmin=0, vmax=1, ax=ax2)\n",
    "ax2.set_title('Late Task Period Coherence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot difference\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(late_coh - early_coh, xticklabels=areas, yticklabels=areas,\n",
    "            cmap='RdBu_r', center=0)\n",
    "plt.title('Change in Coherence (Late - Early)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 