{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Analysis Pipeline for Steinmetz Dataset\n",
    "\n",
    "This notebook demonstrates how to use the automated pipeline for batch processing, including:\n",
    "1. Processing multiple sessions automatically\n",
    "2. Generating standardized visualizations\n",
    "3. Exporting results in a structured format\n",
    "4. Creating summary reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pipeline import AnalysisPipeline\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = f'../results/batch_analysis_{timestamp}'\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = AnalysisPipeline(output_dir=output_dir)\n",
    "\n",
    "# Define sessions to analyze\n",
    "session_indices = [11, 12, 13]  # Example sessions\n",
    "print(f\"Will analyze sessions: {session_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single Session Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process a single session with all analyses\n",
    "session_results = pipeline.process_session(\n",
    "    session_idx=11,\n",
    "    analyses=['basic', 'lfp', 'population', 'behavior', 'cross_regional']\n",
    ")\n",
    "\n",
    "print(\"\\nAnalyses completed for session 11:\")\n",
    "for analysis_type, results in session_results.items():\n",
    "    if isinstance(results, dict):\n",
    "        print(f\"\\n{analysis_type}:\")\n",
    "        for key in results.keys():\n",
    "            print(f\"  - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process multiple sessions in parallel\n",
    "batch_results = pipeline.batch_process(\n",
    "    session_indices=session_indices,\n",
    "    analyses=['basic', 'lfp', 'population'],  # Subset of analyses for example\n",
    "    n_workers=3\n",
    ")\n",
    "\n",
    "print(\"\\nBatch processing completed.\")\n",
    "print(\"Results available for sessions:\", list(batch_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Summary and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_summary_plots(batch_results):\n",
    "    \"\"\"Create summary plots across all sessions.\"\"\"\n",
    "    # Example: Compare PCA explained variance across sessions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for session_idx, results in batch_results.items():\n",
    "        if 'population' in results:\n",
    "            explained_var = results['population']['explained_variance']\n",
    "            plt.plot(np.cumsum(explained_var), \n",
    "                    label=f'Session {session_idx}')\n",
    "    \n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('PCA Explained Variance Across Sessions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create summary plots\n",
    "create_summary_plots(batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def export_summary_report(batch_results, output_dir):\n",
    "    \"\"\"Create and export a summary report of the analyses.\"\"\"\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'n_sessions': len(batch_results),\n",
    "        'session_summaries': {}\n",
    "    }\n",
    "    \n",
    "    for session_idx, results in batch_results.items():\n",
    "        session_summary = {\n",
    "            'analyses_completed': list(results.keys()),\n",
    "            'error': results.get('error', None)\n",
    "        }\n",
    "        \n",
    "        # Add analysis-specific metrics\n",
    "        if 'population' in results:\n",
    "            n_components_80 = np.where(\n",
    "                np.cumsum(results['population']['explained_variance']) >= 0.8\n",
    "            )[0][0] + 1\n",
    "            session_summary['n_components_80_var'] = int(n_components_80)\n",
    "        \n",
    "        summary['session_summaries'][str(session_idx)] = session_summary\n",
    "    \n",
    "    # Save summary report\n",
    "    report_path = os.path.join(output_dir, 'analysis_summary.json')\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Export summary report\n",
    "summary = export_summary_report(batch_results, output_dir)\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Custom analysis configuration\n",
    "custom_config = {\n",
    "    'basic': {\n",
    "        'time_window': (-0.5, 1.0),\n",
    "        'bin_size': 0.01\n",
    "    },\n",
    "    'lfp': {\n",
    "        'freq_bands': {\n",
    "            'theta': (4, 8),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 80)\n",
    "        }\n",
    "    },\n",
    "    'population': {\n",
    "        'n_components': 10,\n",
    "        'scale_data': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process a session with custom configuration\n",
    "custom_results = pipeline.process_session(\n",
    "    session_idx=11,\n",
    "    analyses=['basic', 'lfp', 'population'],\n",
    "    config=custom_config\n",
    ")\n",
    "\n",
    "print(\"\\nCustom analysis completed with configuration:\")\n",
    "print(json.dumps(custom_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def monitor_analysis_performance(batch_results):\n",
    "    \"\"\"Monitor and report analysis performance metrics.\"\"\"\n",
    "    performance_metrics = {\n",
    "        'total_sessions': len(batch_results),\n",
    "        'successful_sessions': sum(1 for r in batch_results.values() if 'error' not in r),\n",
    "        'failed_sessions': sum(1 for r in batch_results.values() if 'error' in r),\n",
    "        'analyses_completed': {}\n",
    "    }\n",
    "    \n",
    "    # Count completed analyses\n",
    "    for results in batch_results.values():\n",
    "        for analysis in results.keys():\n",
    "            if analysis != 'error':\n",
    "                performance_metrics['analyses_completed'][analysis] = \\\n",
    "                    performance_metrics['analyses_completed'].get(analysis, 0) + 1\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(f\"Total sessions processed: {performance_metrics['total_sessions']}\")\n",
    "    print(f\"Successful sessions: {performance_metrics['successful_sessions']}\")\n",
    "    print(f\"Failed sessions: {performance_metrics['failed_sessions']}\")\n",
    "    print(\"\\nAnalyses completed:\")\n",
    "    for analysis, count in performance_metrics['analyses_completed'].items():\n",
    "        print(f\"  {analysis}: {count} sessions\")\n",
    "\n",
    "# Monitor performance\n",
    "monitor_analysis_performance(batch_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 